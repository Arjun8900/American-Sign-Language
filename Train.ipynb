{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 100, 100, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING X, Y\n",
    "from keras import models, layers\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "TRAIN_DIR = \"C:/Users/Admin/Documents/NOTEBOOK/ASL/Images_Gray\"\n",
    "\n",
    "num_classes=24\n",
    "IMG_SIZE = 100\n",
    "def vectorize_data(TRAIN_DIR):\n",
    "    result = []\n",
    "    labels = []\n",
    "    for label in os.listdir(TRAIN_DIR):\n",
    "        path=\"\"\n",
    "        path=os.path.join(TRAIN_DIR, label)\n",
    "        for img in os.listdir(path):\n",
    "            path2=\"\"\n",
    "            path2 = os.path.join(path, img)\n",
    "            i = cv2.imread(path2)\n",
    "            #i = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            i = cv2.resize(cv2.imread(path2, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "            \n",
    "            result.append(i)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return result, labels\n",
    "\n",
    "x, y =vectorize_data(TRAIN_DIR)\n",
    "x_train = np.array(x)\n",
    "y_train = np.array(y)\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "dictonary = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'I':8, 'K':9, 'L':10, 'M':11, 'N':12, 'O':13, 'P':14, \n",
    "            'Q':15, 'R':16, 'S':17, 'T':18, 'U':19, 'V':20, 'W':21, 'X':22, 'Y':23}\n",
    "num_classes=24\n",
    "keys, inv = np.unique(y_train, return_inverse=True)\n",
    "vals = np.array([dictonary[key] for key in keys])\n",
    "y_train_new = vals[inv]\n",
    "y_train_new_cat = to_categorical(y_train_new, num_classes)\n",
    "\n",
    "\n",
    "'''\n",
    "keys, inv = np.unique(y_test, return_inverse=True)\n",
    "vals = np.array([dictonary[key] for key in keys])\n",
    "y_test_new = vals[inv]\n",
    "y_test_new_cat = to_categorical(y_test_new,num_classes=24)\n",
    "'''\n",
    "# SHUFFLE\n",
    "def unison_shuffled_copies(a, b):\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "x_new,y_new = unison_shuffled_copies(x_train,y_train_new_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CREATION\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "IMG_SIZE = 100\n",
    "\n",
    "num_classes = 24\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (2,2), input_shape=(IMG_SIZE, IMG_SIZE, 1), activation='relu'))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=SGD(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#np.expand_dims(i, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 562 samples, validate on 63 samples\n",
      "Epoch 1/30\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 14.0792 - acc: 0.0498 - val_loss: 5.8910 - val_acc: 0.0794\n",
      "Epoch 2/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 3.7736 - acc: 0.1192 - val_loss: 2.7643 - val_acc: 0.1746\n",
      "Epoch 3/30\n",
      "562/562 [==============================] - 8s 15ms/step - loss: 2.4543 - acc: 0.3025 - val_loss: 2.2461 - val_acc: 0.3016\n",
      "Epoch 4/30\n",
      "562/562 [==============================] - 8s 15ms/step - loss: 1.9544 - acc: 0.4466 - val_loss: 2.0362 - val_acc: 0.3333\n",
      "Epoch 5/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 1.6133 - acc: 0.4858 - val_loss: 1.7637 - val_acc: 0.4921\n",
      "Epoch 6/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 1.3445 - acc: 0.6032 - val_loss: 1.5072 - val_acc: 0.4921\n",
      "Epoch 7/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 1.1020 - acc: 0.6637 - val_loss: 1.5846 - val_acc: 0.4286\n",
      "Epoch 8/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.9060 - acc: 0.7278 - val_loss: 1.4002 - val_acc: 0.6349\n",
      "Epoch 9/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.7790 - acc: 0.7740 - val_loss: 1.3736 - val_acc: 0.5873\n",
      "Epoch 10/30\n",
      "562/562 [==============================] - 8s 13ms/step - loss: 0.6997 - acc: 0.7758 - val_loss: 1.2918 - val_acc: 0.5873\n",
      "Epoch 11/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.5601 - acc: 0.8345 - val_loss: 1.2932 - val_acc: 0.5714\n",
      "Epoch 12/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.4571 - acc: 0.8683 - val_loss: 1.1900 - val_acc: 0.6349\n",
      "Epoch 13/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.3781 - acc: 0.8897 - val_loss: 1.2565 - val_acc: 0.6190\n",
      "Epoch 14/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.3986 - acc: 0.8754 - val_loss: 1.2100 - val_acc: 0.6508\n",
      "Epoch 15/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.3456 - acc: 0.9004 - val_loss: 1.0303 - val_acc: 0.6984\n",
      "Epoch 16/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.2543 - acc: 0.9181 - val_loss: 1.2465 - val_acc: 0.6984\n",
      "Epoch 17/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.2590 - acc: 0.9342 - val_loss: 1.0746 - val_acc: 0.6984\n",
      "Epoch 18/30\n",
      "562/562 [==============================] - 8s 15ms/step - loss: 0.2215 - acc: 0.9520 - val_loss: 1.1284 - val_acc: 0.6984\n",
      "Epoch 19/30\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.2173 - acc: 0.9288 - val_loss: 1.1694 - val_acc: 0.6508 4s\n",
      "Epoch 20/30\n",
      "562/562 [==============================] - 8s 15ms/step - loss: 0.1925 - acc: 0.9520 - val_loss: 1.2269 - val_acc: 0.6667\n",
      "Epoch 21/30\n",
      "562/562 [==============================] - 8s 15ms/step - loss: 0.1979 - acc: 0.9342 - val_loss: 1.1609 - val_acc: 0.6667\n",
      "Epoch 22/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.1698 - acc: 0.9484 - val_loss: 1.0347 - val_acc: 0.7302\n",
      "Epoch 23/30\n",
      "562/562 [==============================] - 8s 15ms/step - loss: 0.1437 - acc: 0.9662 - val_loss: 1.1277 - val_acc: 0.6984\n",
      "Epoch 24/30\n",
      "562/562 [==============================] - 9s 15ms/step - loss: 0.1223 - acc: 0.9680 - val_loss: 1.0468 - val_acc: 0.7143\n",
      "Epoch 25/30\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.1448 - acc: 0.9520 - val_loss: 1.1716 - val_acc: 0.7143\n",
      "Epoch 26/30\n",
      "562/562 [==============================] - 11s 19ms/step - loss: 0.1135 - acc: 0.9662 - val_loss: 1.0590 - val_acc: 0.7619\n",
      "Epoch 27/30\n",
      "562/562 [==============================] - 10s 18ms/step - loss: 0.1044 - acc: 0.9733 - val_loss: 1.0354 - val_acc: 0.7460\n",
      "Epoch 28/30\n",
      "562/562 [==============================] - 10s 17ms/step - loss: 0.1230 - acc: 0.9662 - val_loss: 1.0883 - val_acc: 0.7143\n",
      "Epoch 29/30\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.1071 - acc: 0.9698 - val_loss: 1.1085 - val_acc: 0.6984\n",
      "Epoch 30/30\n",
      "562/562 [==============================] - 8s 15ms/step - loss: 0.0920 - acc: 0.9769 - val_loss: 1.0280 - val_acc: 0.7143\n"
     ]
    }
   ],
   "source": [
    "# Training Data \n",
    "\n",
    "model.fit(x_new, y_new, epochs = 30, validation_split = 0.1, shuffle = True, batch_size = 2)\n",
    "model.save(\"Twentyfive_class.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
